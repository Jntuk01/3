
 #2nd experiment
import csv
with open("a.csv") as f: csv_file=csv.reader(f) data=list(csv_file) s=data[1][:-1]
g=[['?' for i in range(len(s))] for j in range(len(s))]
for i in data:
if i[-1]=="yes":
for j in range(len(s)):
if i[j]!=s[j]:
s[j]='?'
g[j][j]='?'
elif i[-1]=="no":
for j in range(len(s)):
if i[j]!=s[j]:
g[j][j]=s[j]
else:
g[j][j]="?"
print("\n Steps of candidate eliminaton algorithm",data.index(i)+1) print(s)
print(g) gh=[]
for i in g:
for j in i:
if j!='?':
gh.append(i)
break
print("\nFinal specific hypothesis:\n",s) print("\nFinal general hypothesis:\n",gh)

 

Steps of candidate eliminaton algorithm 1
['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same']
[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?',
'?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]

Steps of candidate eliminaton algorithm 2
['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same']
[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?',
'?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]

Steps of candidate eliminaton algorithm 3
['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same']
[['Sunny', '?', '?', '?', '?', '?'], ['?', 'Warm', '?', '?', '?', '?'],
['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', 'Same']]

Steps of candidate eliminaton algorithm 4 ['Sunny', 'Warm', '?', 'Strong', '?', '?']
[['Sunny', '?', '?', '?', '?', '?'], ['?', 'Warm', '?', '?', '?', '?'],
['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?',
'?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]

Final specific hypothesis:
['Sunny', 'Warm', '?', 'Strong', '?', '?']

Final general hypothesis:
[['Sunny', '?', '?', '?', '?', '?'], ['?', 'Warm', '?', '?', '?', '?']]
 

 
Predicted values:
[2 1 0 2	0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0]
[[11 0	0]
[ 0 13	0]
[ 0 0	6]]
Correct	Prediction:
1.0
Wrong Prediction:
0.0
 

In [10]:


['Sunny', 'Warm', 'Normal', 'Strong', 'Warm', 'Same', 'yes']
['Sunny', 'Warm', 'High', 'Strong', 'Warm', 'Same', 'yes']
['Rainy', 'Cold', 'High', 'Strong', 'Warm', 'Change', 'no']
['Sunny', 'Warm', 'High', 'Strong', 'Cool', 'Change', 'yes']

The initial value of hypothesis:
['0', '0', '0', '0', '0', '0']

Find S: Finding a Maximally Specific Hypothesis

For Training instance No:0 the hypothesis is ['Sunny', 'Warm', 'Norma l', 'Strong', 'Warm', 'Same']
For Training instance No:1 the hypothesis is ['Sunny', 'Warm', '?', 'St rong', 'Warm', 'Same']
For Training instance No:2 the hypothesis is ['Sunny', 'Warm', '?', 'St rong', 'Warm', 'Same']
For Training instance No:3 the hypothesis is ['Sunny', 'Warm', '?', 'St rong', '?', '?']
 
#3rd experiment
import numpy as np
import pandas as pd
from sklearn import tree
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier from sklearn.preprocessing import StandardScaler from sklearn.metrics import confusion_matrix
iris = datasets.load_iris() x=iris.data
y=iris.target
x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.2, random_state=0) st_x= StandardScaler()
x_train= st_x.fit_transform(x_train) x_test= st_x.transform(x_test)
clf_entropy = DecisionTreeClassifier(criterion = "entropy", random_state = 100,max_depth clf_entropy.fit(x_train, y_train)
clf_gini = DecisionTreeClassifier(criterion = "gini",random_state = 100,max_depth=3, min_ clf_gini.fit(x_train, y_train)
y_pred = clf_entropy.predict(x_test) print("Predicted values:")
print(y_pred)
from sklearn.metrics import accuracy_score print("Accuracy score:")
print(accuracy_score(y_test,y_pred))
cm=np.array(confusion_matrix(y_test,y_pred)) tree.plot_tree(clf_entropy)
text_representation = tree.export_text(clf_entropy) print(text_representation)
Predicted values:
[2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0]
Accuracy score:
1.0
|--- feature_2 <= -0.82
|	|--- class: 0
|--- feature_2 > -0.82
|	|--- feature_3 <= 0.67
|	|	|--- feature_2 <= 0.64
|	|	|	|--- class: 1
|	|	|--- feature_2 > 0.64
|	|	|	|--- class: 2
|	|--- feature_3 > 0.67
|	|	|--- feature_0 <= 0.08
|	|	|	|--- class: 2
|	|	|--- feature_0 > 0.08
|	|	|	|--- class: 2
 

 
 
#9th experiment
from sklearn.cluster import KMeans
from sklearn.mixture import GaussianMixture
import sklearn.metrics as metrics
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
names = ['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width', 'Class'] dataset = pd.read_csv("8-dataset.csv", names=names)
X = dataset.iloc[:, :-1]
label = {'Iris-setosa': 0,'Iris-versicolor': 1, 'Iris-virginica': 2} y = [label[c] for c in dataset.iloc[:, -1]]
plt.figure(figsize=(14,7))
colormap=np.array(['red','lime','black']) plt.subplot(1,3,1)
plt.title('Real')
plt.scatter(X.Petal_Length,X.Petal_Width,c=colormap[y]) model=KMeans(n_clusters=3, random_state=0).fit(X)
plt.subplot(1,3,2) plt.title('KMeans')
plt.scatter(X.Petal_Length,X.Petal_Width,c=colormap[model.labels_])
print('The accuracy score of K-Mean: ',metrics.accuracy_score(y, model.labels_))
print('The Confusion matrixof K-Mean:\n',metrics.confusion_matrix(y, model.labels_)) gmm=GaussianMixture(n_components=3, random_state=0).fit(X)
y_cluster_gmm=gmm.predict(X) plt.subplot(1,3,3)
plt.title('GMM Classification')
plt.scatter(X.Petal_Length,X.Petal_Width,c=colormap[y_cluster_gmm])
print('The accuracy score of EM: ',metrics.accuracy_score(y, y_cluster_gmm))
print('The Confusion matrix of EM:\n ',metrics.confusion_matrix(y, y_cluster_gmm))
The accuracy score of K-Mean: 0.24 The Confusion matrixof K-Mean:
[[ 0 50 0]
[48 0 2]
[14 0 36]]
The accuracy score of EM: 0.36666666666666664 The Confusion matrix of EM:
[[50	0 0]
[ 0 5	45]
[ 0 50	0]]
 

 
 

#7th experiment
import numpy as np import pandas as pd import csv
from pgmpy.models import BayesianModel
from pgmpy.estimators import MaximumLikelihoodEstimator
from pgmpy.inference import VariableElimination

heartDisease = pd.read_csv('heart.csv')
heartDisease = heartDisease.replace('?',np.nan)

model= BayesianModel([('age','heartdisease'),('sex','heartdisease'),('exang','heartdiseas print('\nLearning CPD using Maximum likelihood estimators')
model.fit(heartDisease,estimator=MaximumLikelihoodEstimator)

print('\n Inferencing with Bayesian Network:')
HeartDiseasetest_infer = VariableElimination(model)

print('\n 1. Probability of HeartDisease given evidence= restecg')
q1=HeartDiseasetest_infer.query(variables=['heartdisease'],evidence={'restecg':1}) print(q1)

print('\n 2. Probability of HeartDisease given evidence= cp ')
q2=HeartDiseasetest_infer.query(variables=['heartdisease'],evidence={'cp':2}) print(q2)

 		
 
C:\Users\Admin\anaconda3\lib\site-packages\pgmpy\models\BayesianModel.py: 8: FutureWarning: BayesianModel has been renamed to BayesianNetwork. Pleas e use BayesianNetwork class, BayesianModel will be removed in future.
warnings.warn(

Learning CPD using Maximum likelihood estimators Inferencing with Bayesian Network:
1.	Probability of HeartDisease given evidence= restecg

 
Finding Elimination Order: : 0%
 
0/4 [00:00<?, ?
it/s]
 

 
Eliminating: cp: 100%
 
4/4 [00:00<00:00,
74.07it/s]
 
+-----------------+	+
| heartdisease	|	phi(heartdisease) |
+=================+=====================+
| heartdisease(0) |	0.1012 |
+-----------------+	+
| heartdisease(1) |	0.0000 |
+-----------------+	+
| heartdisease(2) |	0.2392 |
+-----------------+	+
| heartdisease(3) |	0.2015 |
+-----------------+	+
| heartdisease(4) |	0.4581 |
+-----------------+	+

2.	Probability of HeartDisease given evidence= cp

 
Finding Elimination Order: : 0%
 
0/3 [00:00<?, ?
it/s]
 

 
Eliminating: age: 100%
 
3/3 [00:00<00:00,
78.94it/s]
 
+-----------------+	+
| heartdisease	|	phi(heartdisease) |
+=================+=====================+
| heartdisease(0) |	0.3610 |
+-----------------+	+
| heartdisease(1) |	0.2159 |
+-----------------+	+
| heartdisease(2) |	0.1373 |
+-----------------+	+
| heartdisease(3) |	0.1537 |
+-----------------+	+
| heartdisease(4) |	0.1321 |
+-----------------+	+
 
#10th experiment
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
def kernel(point, xmat, k): m,n = np.shape(xmat)
weights = np.mat(np.eye((m)))
for j in range(m):
diff = point - X[j]
weights[j,j] = np.exp(diff*diff.T/(-2.0*k**2))
return weights
def localWeight(point, xmat, ymat, k): wei = kernel(point,xmat,k)
W = (X.T*(wei*X)).I*(X.T*(wei*ymat.T))
return W

def localWeightRegression(xmat, ymat, k): m,n = np.shape(xmat)
ypred = np.zeros(m)
for i in range(m):
ypred[i] = xmat[i]*localWeight(xmat[i],xmat,ymat,k)
return ypred

# load data points
data = pd.read_csv('10-dataset.csv') bill = np.array(data.total_bill)
tip = np.array(data.tip)

#preparing and add 1 in bill
mbill = np.mat(bill) mtip = np.mat(tip)

m= np.shape(mbill)[1]
one = np.mat(np.ones(m))
X = np.hstack((one.T,mbill.T))
#set k here
ypred = localWeightRegression(X,mtip,0.5) SortIndex = X[:,1].argsort(0)
xsort = X[SortIndex][:,0]

fig = plt.figure()
ax = fig.add_subplot(1,1,1)
ax.scatter(bill,tip, color='green')
ax.plot(xsort[:,1],ypred[SortIndex], color = 'red', linewidth=5) plt.xlabel('Total bill')
plt.ylabel('Tip') plt.show();
 

 
 

In [15]:

The dimensions of the dataset (18, 2)

the total number of Training Data : (13,) the total number of Test Data : (5,)
Accuracy of the classifier is 0.8

Confusion matrix [[2 0]
[1 2]]

The value of Precision 1.0

The value of Recall 0.6666666666666666
 

In [46]:

 
The first 5 values of data is :
	day	outlook	temp	humidity	wind	play
0	D1	Sunny	Hot	High	Weak	No
1	D2	Sunny	Hot	High	Strong	No
2	D3	Overcast	Hot	High	Weak	Yes
3	D4	Rain	Mild	High	Weak	Yes
4	D5	Rain	Cool	Normal	Weak	Yes

The First 5 values of train data is
	day	outlook	temp	humidity	wind
0	D1	Sunny	Hot	High	Weak
1	D2	Sunny	Hot	High	Strong
2	D3	Overcast	Hot	High	Weak
3	D4	Rain	Mild	High	Weak
4	D5	Rain	Cool	Normal	Weak

The first 5 values of Train output is
0	No
1	No
2	Yes
3	Yes
4	Yes
Name: play, dtype: object

Now the Train data is :
day outlook temp humidity wind
0 D1	2	1	0	1
1 D2	2	1	0	0
2 D3	0	1	0	1
3 D4	1	2	0	1
4 D5	1	0	1	1

Now the Train output is
<bound method LabelEncoder.fit_transform of LabelEncoder()>
C:\Users\Admin\anaconda3\lib\site-packages\pandas\core\generic.py:5494: Se ttingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-doc s/stable/user_guide/indexing.html#returning-a-view-versus-a-copy (https:// pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a- view-versus-a-copy)
self[name] = value

